{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f74845f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132802490\n"
     ]
    }
   ],
   "source": [
    "# def get_file_counts(filename):\n",
    "#     with open(filename) as fp:\n",
    "#         count = 0\n",
    "#         for _ in fp:\n",
    "#             count += 1\n",
    "#     return count\n",
    "\n",
    "file_name_list = ['2015_32384541_32M-006.csv', '2016_31758353_31M-007.csv', '2017_24987298_24M-004.csv',\\\n",
    "                  '2018_20731058_20M-005.csv', '2019_16476247_16M-003.csv', '2020_3888214_3M.csv', '2021_2576772_2M.csv']\n",
    "\n",
    "\n",
    "# file_counts = []\n",
    "\n",
    "# for i in file_name_list:\n",
    "#     file_counts.append(get_file_counts(i))\n",
    "\n",
    "# print(file_counts)\n",
    "\n",
    "file_counts = [32384542, 31758354, 24987299, 20731059, 16476248, 3888215, 2576773]\n",
    "total_size = sum(file_counts)\n",
    "print(total_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a358435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f4ceeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_generator(chunks):\n",
    "    global file_name_list\n",
    "    while True:\n",
    "        for i in range(2, 4):\n",
    "            f = file_name_list[i]\n",
    "#             f = file_name_list[4]\n",
    "            for data in pd.read_csv(f, chunksize=chunks):\n",
    "                data = data[data['Trip Seconds'].notna()]\n",
    "                data = data[data['Trip Miles'].notna()]\n",
    "                data = data[data['Fare'].notna()]\n",
    "                data = data[data['Trip Start Timestamp'].notna()]\n",
    "                data['month'] = pd.to_datetime(data['Trip Start Timestamp']).dt.month\n",
    "                x = data[['Trip Seconds', 'Trip Miles', 'month']].to_numpy()\n",
    "                y = data['Fare'].to_numpy()\n",
    "                yield x, y\n",
    "            \n",
    "def validator_generator(chunks):\n",
    "    while True:\n",
    "        for data in pd.read_csv('2021_2576772_2M.csv', chunksize=chunks):\n",
    "            data = data[data['Trip Seconds'].notna()]\n",
    "            data = data[data['Trip Miles'].notna()]\n",
    "            data = data[data['Fare'].notna()]\n",
    "            data = data[data['Trip Start Timestamp'].notna()]\n",
    "            data['month'] = pd.to_datetime(data['Trip Start Timestamp']).dt.month\n",
    "            x = data[['Trip Seconds', 'Trip Miles', 'month']].to_numpy()\n",
    "            y = data['Fare'].to_numpy()\n",
    "            yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c91937ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_model = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model.add(Dense(16, kernel_initializer='normal',input_dim = 3, activation='relu'))\n",
    "\n",
    "# The Hidden Layer :\n",
    "NN_model.add(Dense(32, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(32, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2409acc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pulak\\AppData\\Local\\Temp/ipykernel_3304/3312326068.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  NN_model.fit_generator(my_generator(chunksize),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3047/3047 - 1324s - loss: 2.1603 - mean_absolute_error: 2.1603 - val_loss: 3.7293 - val_mean_absolute_error: 3.7293 - 1324s/epoch - 434ms/step\n",
      "Epoch 2/3\n",
      "3047/3047 - 1322s - loss: 1.5723 - mean_absolute_error: 1.5723 - val_loss: 3.7142 - val_mean_absolute_error: 3.7142 - 1322s/epoch - 434ms/step\n",
      "Epoch 3/3\n",
      "3047/3047 - 1321s - loss: 1.5142 - mean_absolute_error: 1.5142 - val_loss: 4.2288 - val_mean_absolute_error: 4.2288 - 1321s/epoch - 434ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dc68a82820>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_length = file_counts[2] + file_counts[3]\n",
    "chunksize = 15000\n",
    "\n",
    "NN_model.fit_generator(my_generator(chunksize),\n",
    "          steps_per_epoch=file_length//chunksize,\n",
    "          epochs=3,\n",
    "          verbose=2,\n",
    "          validation_data=validator_generator(chunksize),\n",
    "          validation_steps=50\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca95e844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.143008"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_fare(time, distance, month):\n",
    "    return NN_model.predict([[time, distance, month]])[0][0]\n",
    "\n",
    "\n",
    "predict_fare(1000, 0.5, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51ea3d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: NN_model\\assets\n"
     ]
    }
   ],
   "source": [
    "NN_model.save('NN_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kerasregression] *",
   "language": "python",
   "name": "conda-env-kerasregression-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
