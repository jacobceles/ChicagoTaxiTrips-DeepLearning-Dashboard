{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f74845f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132802490\n"
     ]
    }
   ],
   "source": [
    "# def get_file_counts(filename):\n",
    "#     with open(filename) as fp:\n",
    "#         count = 0\n",
    "#         for _ in fp:\n",
    "#             count += 1\n",
    "#     return count\n",
    "\n",
    "file_name_list = ['2015_32384541_32M-006.csv', '2016_31758353_31M-007.csv', '2017_24987298_24M-004.csv',\\\n",
    "                  '2018_20731058_20M-005.csv', '2019_16476247_16M-003.csv', '2020_3888214_3M.csv', '2021_2576772_2M.csv']\n",
    "\n",
    "\n",
    "# file_counts = []\n",
    "\n",
    "# for i in file_name_list:\n",
    "#     file_counts.append(get_file_counts(i))\n",
    "\n",
    "# print(file_counts)\n",
    "\n",
    "file_counts = [32384542, 31758354, 24987299, 20731059, 16476248, 3888215, 2576773]\n",
    "total_size = sum(file_counts)\n",
    "print(total_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a358435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f4ceeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_generator(chunks, file_list):\n",
    "    while True:\n",
    "        for f in file_list:\n",
    "            for data in pd.read_csv(f, chunksize=chunks):\n",
    "                data = data[data['Trip Seconds'].notna()]\n",
    "                data = data[data['Trip Miles'].notna()]\n",
    "                data = data[data['Fare'].notna()]\n",
    "                data = data[data['Trip Start Timestamp'].notna()]\n",
    "                data['month'] = pd.to_datetime(data['Trip Start Timestamp']).dt.month\n",
    "                x = data[['Trip Seconds', 'Trip Miles', 'month']].to_numpy()\n",
    "                y = data['Fare'].to_numpy()\n",
    "                yield x, y\n",
    "            \n",
    "\n",
    "\n",
    "def get_validation_data(validation_size, file_size, file_list, p):\n",
    "    if p == 0:\n",
    "        p = validation_size/file_size\n",
    "    li = []\n",
    "    for f in file_list:\n",
    "        df = pd.read_csv(f, header=0, skiprows=lambda i: i>0 and random.random() > p)\n",
    "        li.append(df)\n",
    "    if len(li) > 1:\n",
    "        data = pd.concat(li, axis=0, ignore_index=True)\n",
    "    else:\n",
    "        data = li[0]\n",
    "    data = data[data['Trip Seconds'].notna()]\n",
    "    data = data[data['Trip Miles'].notna()]\n",
    "    data = data[data['Fare'].notna()]\n",
    "    data = data[data['Trip Start Timestamp'].notna()]\n",
    "    data['month'] = pd.to_datetime(data['Trip Start Timestamp']).dt.month\n",
    "    x = data[['Trip Seconds', 'Trip Miles', 'month']].to_numpy()\n",
    "    y = data['Fare'].to_numpy()\n",
    "    return x, y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d1d9cb",
   "metadata": {},
   "source": [
    "# Large Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c91937ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN_model = Sequential()\n",
    "\n",
    "# # The Input Layer :\n",
    "# NN_model.add(Dense(16, kernel_initializer='normal',input_dim = 3, activation='relu'))\n",
    "\n",
    "# # The Hidden Layer :\n",
    "# NN_model.add(Dense(32, kernel_initializer='normal',activation='relu'))\n",
    "# NN_model.add(Dense(32, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# # The Output Layer :\n",
    "# NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2409acc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_length = file_counts[2] + file_counts[3]\n",
    "# file_list = [file_name_list[2], file_name_list[3]]\n",
    "# chunksize = 15000\n",
    "\n",
    "# NN_model.fit_generator(my_generator(chunksize, file_list),\n",
    "#           steps_per_epoch=file_length//chunksize,\n",
    "#           epochs=3,\n",
    "#           verbose=2,\n",
    "#           validation_data=validator_generator(chunksize),\n",
    "#           validation_steps=16476248//chunksize\n",
    "#             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b81473",
   "metadata": {},
   "source": [
    "# 2021 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47f2d555",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_model_2021 = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model_2021.add(Dense(16, kernel_initializer='normal',input_dim = 3, activation='relu'))\n",
    "\n",
    "# The Hidden Layer :\n",
    "NN_model_2021.add(Dense(32, kernel_initializer='normal',activation='relu'))\n",
    "NN_model_2021.add(Dense(32, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model_2021.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "NN_model_2021.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc0ffdf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pulak\\AppData\\Local\\Temp/ipykernel_8688/3908493545.py:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  NN_model_2021.fit_generator(my_generator(chunksize, file_list),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "171/171 - 16s - loss: 4.1086 - mean_absolute_error: 4.1086 - val_loss: 4.0301 - val_mean_absolute_error: 4.0301 - 16s/epoch - 92ms/step\n",
      "Epoch 2/10\n",
      "171/171 - 16s - loss: 3.8082 - mean_absolute_error: 3.8082 - val_loss: 3.7527 - val_mean_absolute_error: 3.7527 - 16s/epoch - 93ms/step\n",
      "Epoch 3/10\n",
      "171/171 - 16s - loss: 3.7696 - mean_absolute_error: 3.7696 - val_loss: 3.4057 - val_mean_absolute_error: 3.4057 - 16s/epoch - 93ms/step\n",
      "Epoch 4/10\n",
      "171/171 - 16s - loss: 3.7234 - mean_absolute_error: 3.7234 - val_loss: 3.3707 - val_mean_absolute_error: 3.3707 - 16s/epoch - 93ms/step\n",
      "Epoch 5/10\n",
      "171/171 - 16s - loss: 3.7150 - mean_absolute_error: 3.7150 - val_loss: 3.5881 - val_mean_absolute_error: 3.5881 - 16s/epoch - 93ms/step\n",
      "Epoch 6/10\n",
      "171/171 - 16s - loss: 3.7114 - mean_absolute_error: 3.7114 - val_loss: 3.4846 - val_mean_absolute_error: 3.4846 - 16s/epoch - 93ms/step\n",
      "Epoch 7/10\n",
      "171/171 - 16s - loss: 3.6350 - mean_absolute_error: 3.6350 - val_loss: 3.2623 - val_mean_absolute_error: 3.2623 - 16s/epoch - 92ms/step\n",
      "Epoch 8/10\n",
      "171/171 - 16s - loss: 3.6868 - mean_absolute_error: 3.6868 - val_loss: 3.2361 - val_mean_absolute_error: 3.2361 - 16s/epoch - 93ms/step\n",
      "Epoch 9/10\n",
      "171/171 - 16s - loss: 3.6148 - mean_absolute_error: 3.6148 - val_loss: 3.3334 - val_mean_absolute_error: 3.3334 - 16s/epoch - 92ms/step\n",
      "Epoch 10/10\n",
      "171/171 - 16s - loss: 3.6404 - mean_absolute_error: 3.6404 - val_loss: 3.4172 - val_mean_absolute_error: 3.4172 - 16s/epoch - 94ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2078ff09cd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_length = file_counts[6]\n",
    "file_list = [file_name_list[6]]\n",
    "chunksize = 15000\n",
    "validation_set = get_validation_data(100000, file_length, file_list, 0)\n",
    "\n",
    "NN_model_2021.fit_generator(my_generator(chunksize, file_list),\n",
    "          steps_per_epoch=file_length//chunksize,\n",
    "          epochs=10,\n",
    "          verbose=2,\n",
    "          validation_data=validation_set, \n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e4bb8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: NN_model_2021\\assets\n"
     ]
    }
   ],
   "source": [
    "NN_model_2021.save('NN_model_2021')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e659cd20",
   "metadata": {},
   "source": [
    "# 2015 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2c60527",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_model_2015 = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model_2015.add(Dense(16, kernel_initializer='normal',input_dim = 3, activation='relu'))\n",
    "\n",
    "# The Hidden Layer :\n",
    "NN_model_2015.add(Dense(32, kernel_initializer='normal',activation='relu'))\n",
    "NN_model_2015.add(Dense(32, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model_2015.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "NN_model_2015.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bfe5d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pulak\\AppData\\Local\\Temp/ipykernel_8688/2611377337.py:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  NN_model_2015.fit_generator(my_generator(chunksize, file_list),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2158/2158 - 1889s - loss: 2.8509 - mean_absolute_error: 2.8509 - val_loss: 2.3865 - val_mean_absolute_error: 2.3865 - 1889s/epoch - 875ms/step\n",
      "Epoch 2/3\n",
      "2158/2158 - 1895s - loss: 2.4085 - mean_absolute_error: 2.4085 - val_loss: 3.9199 - val_mean_absolute_error: 3.9199 - 1895s/epoch - 878ms/step\n",
      "Epoch 3/3\n",
      "2158/2158 - 1884s - loss: 2.3843 - mean_absolute_error: 2.3843 - val_loss: 3.5050 - val_mean_absolute_error: 3.5050 - 1884s/epoch - 873ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x207d2fd12e0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_length = file_counts[0]\n",
    "file_list = [file_name_list[0]]\n",
    "chunksize = 15000\n",
    "validation_set = get_validation_data(100000, file_length, file_list, 0)\n",
    "\n",
    "NN_model_2015.fit_generator(my_generator(chunksize, file_list),\n",
    "          steps_per_epoch=file_length//chunksize,\n",
    "          epochs=3,\n",
    "          verbose=2,\n",
    "          validation_data=validation_set, \n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d393b33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: NN_model_2015\\assets\n"
     ]
    }
   ],
   "source": [
    "NN_model_2015.save('NN_model_2015')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca95e844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fare(model, time, distance, month):\n",
    "    return model.predict([[time, distance, month]])[0][0]\n",
    "\n",
    "\n",
    "# predict_fare(1000, 0.5, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51ea3d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN_model.save('NN_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1ad2ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kerasregression] *",
   "language": "python",
   "name": "conda-env-kerasregression-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
